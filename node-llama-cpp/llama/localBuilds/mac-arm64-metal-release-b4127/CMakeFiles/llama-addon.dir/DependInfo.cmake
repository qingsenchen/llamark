
# Consider dependencies only in project.
set(CMAKE_DEPENDS_IN_PROJECT_ONLY OFF)

# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  )

# The set of dependency files which are needed:
set(CMAKE_DEPENDS_DEPENDENCY_FILES
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonContext.cpp" "CMakeFiles/llama-addon.dir/addon/AddonContext.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonContext.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonGrammar.cpp" "CMakeFiles/llama-addon.dir/addon/AddonGrammar.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonGrammar.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonGrammarEvaluationState.cpp" "CMakeFiles/llama-addon.dir/addon/AddonGrammarEvaluationState.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonGrammarEvaluationState.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonModel.cpp" "CMakeFiles/llama-addon.dir/addon/AddonModel.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonModel.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonModelData.cpp" "CMakeFiles/llama-addon.dir/addon/AddonModelData.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonModelData.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonModelLora.cpp" "CMakeFiles/llama-addon.dir/addon/AddonModelLora.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonModelLora.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/AddonSampler.cpp" "CMakeFiles/llama-addon.dir/addon/AddonSampler.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/AddonSampler.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/addon.cpp" "CMakeFiles/llama-addon.dir/addon/addon.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/addon.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/addonGlobals.cpp" "CMakeFiles/llama-addon.dir/addon/addonGlobals.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/addonGlobals.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/globals/addonLog.cpp" "CMakeFiles/llama-addon.dir/addon/globals/addonLog.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/globals/addonLog.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/globals/addonProgress.cpp" "CMakeFiles/llama-addon.dir/addon/globals/addonProgress.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/globals/addonProgress.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/globals/getGpuInfo.cpp" "CMakeFiles/llama-addon.dir/addon/globals/getGpuInfo.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/globals/getGpuInfo.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/addon/globals/getSwapInfo.cpp" "CMakeFiles/llama-addon.dir/addon/globals/getSwapInfo.cpp.o" "gcc" "CMakeFiles/llama-addon.dir/addon/globals/getSwapInfo.cpp.o.d"
  "/Users/qzx/gitspace/node-llama-cpp/llama/gpuInfo/metal-gpu-info.mm" "CMakeFiles/llama-addon.dir/gpuInfo/metal-gpu-info.mm.o" "gcc" "CMakeFiles/llama-addon.dir/gpuInfo/metal-gpu-info.mm.o.d"
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_LINKED_INFO_FILES
  )

# Targets to which this target links which contain Fortran sources.
set(CMAKE_Fortran_TARGET_FORWARD_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")

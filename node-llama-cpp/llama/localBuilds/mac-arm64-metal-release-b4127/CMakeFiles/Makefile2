# CMAKE generated file: DO NOT EDIT!
# Generated by "Unix Makefiles" Generator, CMake Version 3.31

# Default target executed when no arguments are given to make.
default_target: all
.PHONY : default_target

#=============================================================================
# Special targets provided by cmake.

# Disable implicit rules so canonical targets will work.
.SUFFIXES:

# Disable VCS-based implicit rules.
% : %,v

# Disable VCS-based implicit rules.
% : RCS/%

# Disable VCS-based implicit rules.
% : RCS/%,v

# Disable VCS-based implicit rules.
% : SCCS/s.%

# Disable VCS-based implicit rules.
% : s.%

.SUFFIXES: .hpux_make_needs_suffix_list

# Command-line flag to silence nested $(MAKE).
$(VERBOSE)MAKESILENT = -s

#Suppress display of executed commands.
$(VERBOSE).SILENT:

# A target that is always out of date.
cmake_force:
.PHONY : cmake_force

#=============================================================================
# Set environment variables for the build.

# The shell in which to execute make rules.
SHELL = /bin/sh

# The CMake executable.
CMAKE_COMMAND = /Applications/CMake.app/Contents/bin/cmake

# The command to remove a file.
RM = /Applications/CMake.app/Contents/bin/cmake -E rm -f

# Escaping for special characters.
EQUALS = =

# The top-level source directory on which CMake was run.
CMAKE_SOURCE_DIR = /Users/qzx/gitspace/node-llama-cpp/llama

# The top-level build directory on which CMake was run.
CMAKE_BINARY_DIR = /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127

#=============================================================================
# Directory level rules for the build root directory

# The main recursive "all" target.
all: CMakeFiles/llama-addon.dir/all
all: llama.cpp/all
.PHONY : all

# The main recursive "codegen" target.
codegen: CMakeFiles/llama-addon.dir/codegen
codegen: llama.cpp/codegen
.PHONY : codegen

# The main recursive "preinstall" target.
preinstall: llama.cpp/preinstall
.PHONY : preinstall

# The main recursive "clean" target.
clean: CMakeFiles/llama-addon.dir/clean
clean: llama.cpp/clean
.PHONY : clean

#=============================================================================
# Directory level rules for directory llama.cpp

# Recursive "all" directory target.
llama.cpp/all: llama.cpp/ggml/all
llama.cpp/all: llama.cpp/src/all
llama.cpp/all: llama.cpp/common/all
.PHONY : llama.cpp/all

# Recursive "codegen" directory target.
llama.cpp/codegen: llama.cpp/ggml/codegen
llama.cpp/codegen: llama.cpp/src/codegen
llama.cpp/codegen: llama.cpp/common/codegen
.PHONY : llama.cpp/codegen

# Recursive "preinstall" directory target.
llama.cpp/preinstall: llama.cpp/ggml/preinstall
llama.cpp/preinstall: llama.cpp/src/preinstall
llama.cpp/preinstall: llama.cpp/common/preinstall
.PHONY : llama.cpp/preinstall

# Recursive "clean" directory target.
llama.cpp/clean: llama.cpp/ggml/clean
llama.cpp/clean: llama.cpp/src/clean
llama.cpp/clean: llama.cpp/common/clean
.PHONY : llama.cpp/clean

#=============================================================================
# Directory level rules for directory llama.cpp/common

# Recursive "all" directory target.
llama.cpp/common/all: llama.cpp/common/CMakeFiles/build_info.dir/all
llama.cpp/common/all: llama.cpp/common/CMakeFiles/common.dir/all
.PHONY : llama.cpp/common/all

# Recursive "codegen" directory target.
llama.cpp/common/codegen: llama.cpp/common/CMakeFiles/build_info.dir/codegen
llama.cpp/common/codegen: llama.cpp/common/CMakeFiles/common.dir/codegen
.PHONY : llama.cpp/common/codegen

# Recursive "preinstall" directory target.
llama.cpp/common/preinstall:
.PHONY : llama.cpp/common/preinstall

# Recursive "clean" directory target.
llama.cpp/common/clean: llama.cpp/common/CMakeFiles/build_info.dir/clean
llama.cpp/common/clean: llama.cpp/common/CMakeFiles/common.dir/clean
.PHONY : llama.cpp/common/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml

# Recursive "all" directory target.
llama.cpp/ggml/all: llama.cpp/ggml/src/all
.PHONY : llama.cpp/ggml/all

# Recursive "codegen" directory target.
llama.cpp/ggml/codegen: llama.cpp/ggml/src/codegen
.PHONY : llama.cpp/ggml/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/preinstall: llama.cpp/ggml/src/preinstall
.PHONY : llama.cpp/ggml/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/clean: llama.cpp/ggml/src/clean
.PHONY : llama.cpp/ggml/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml/src

# Recursive "all" directory target.
llama.cpp/ggml/src/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
llama.cpp/ggml/src/all: llama.cpp/ggml/src/CMakeFiles/ggml.dir/all
llama.cpp/ggml/src/all: llama.cpp/ggml/src/ggml-cpu/all
llama.cpp/ggml/src/all: llama.cpp/ggml/src/ggml-amx/all
llama.cpp/ggml/src/all: llama.cpp/ggml/src/ggml-blas/all
llama.cpp/ggml/src/all: llama.cpp/ggml/src/ggml-metal/all
.PHONY : llama.cpp/ggml/src/all

# Recursive "codegen" directory target.
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/codegen
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/CMakeFiles/ggml.dir/codegen
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/ggml-cpu/codegen
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/ggml-amx/codegen
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/ggml-blas/codegen
llama.cpp/ggml/src/codegen: llama.cpp/ggml/src/ggml-metal/codegen
.PHONY : llama.cpp/ggml/src/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/src/preinstall: llama.cpp/ggml/src/ggml-cpu/preinstall
llama.cpp/ggml/src/preinstall: llama.cpp/ggml/src/ggml-amx/preinstall
llama.cpp/ggml/src/preinstall: llama.cpp/ggml/src/ggml-blas/preinstall
llama.cpp/ggml/src/preinstall: llama.cpp/ggml/src/ggml-metal/preinstall
.PHONY : llama.cpp/ggml/src/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/clean
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/CMakeFiles/ggml.dir/clean
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/ggml-cpu/clean
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/ggml-amx/clean
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/ggml-blas/clean
llama.cpp/ggml/src/clean: llama.cpp/ggml/src/ggml-metal/clean
.PHONY : llama.cpp/ggml/src/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml/src/ggml-amx

# Recursive "all" directory target.
llama.cpp/ggml/src/ggml-amx/all:
.PHONY : llama.cpp/ggml/src/ggml-amx/all

# Recursive "codegen" directory target.
llama.cpp/ggml/src/ggml-amx/codegen:
.PHONY : llama.cpp/ggml/src/ggml-amx/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/src/ggml-amx/preinstall:
.PHONY : llama.cpp/ggml/src/ggml-amx/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/src/ggml-amx/clean:
.PHONY : llama.cpp/ggml/src/ggml-amx/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml/src/ggml-blas

# Recursive "all" directory target.
llama.cpp/ggml/src/ggml-blas/all: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
.PHONY : llama.cpp/ggml/src/ggml-blas/all

# Recursive "codegen" directory target.
llama.cpp/ggml/src/ggml-blas/codegen: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-blas/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/src/ggml-blas/preinstall:
.PHONY : llama.cpp/ggml/src/ggml-blas/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/src/ggml-blas/clean: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-blas/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml/src/ggml-cpu

# Recursive "all" directory target.
llama.cpp/ggml/src/ggml-cpu/all: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
.PHONY : llama.cpp/ggml/src/ggml-cpu/all

# Recursive "codegen" directory target.
llama.cpp/ggml/src/ggml-cpu/codegen: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-cpu/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/src/ggml-cpu/preinstall:
.PHONY : llama.cpp/ggml/src/ggml-cpu/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/src/ggml-cpu/clean: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-cpu/clean

#=============================================================================
# Directory level rules for directory llama.cpp/ggml/src/ggml-metal

# Recursive "all" directory target.
llama.cpp/ggml/src/ggml-metal/all: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
.PHONY : llama.cpp/ggml/src/ggml-metal/all

# Recursive "codegen" directory target.
llama.cpp/ggml/src/ggml-metal/codegen: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-metal/codegen

# Recursive "preinstall" directory target.
llama.cpp/ggml/src/ggml-metal/preinstall:
.PHONY : llama.cpp/ggml/src/ggml-metal/preinstall

# Recursive "clean" directory target.
llama.cpp/ggml/src/ggml-metal/clean: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-metal/clean

#=============================================================================
# Directory level rules for directory llama.cpp/src

# Recursive "all" directory target.
llama.cpp/src/all: llama.cpp/src/CMakeFiles/llama.dir/all
.PHONY : llama.cpp/src/all

# Recursive "codegen" directory target.
llama.cpp/src/codegen: llama.cpp/src/CMakeFiles/llama.dir/codegen
.PHONY : llama.cpp/src/codegen

# Recursive "preinstall" directory target.
llama.cpp/src/preinstall:
.PHONY : llama.cpp/src/preinstall

# Recursive "clean" directory target.
llama.cpp/src/clean: llama.cpp/src/CMakeFiles/llama.dir/clean
.PHONY : llama.cpp/src/clean

#=============================================================================
# Target rules for target CMakeFiles/llama-addon.dir

# All Build rule for target.
CMakeFiles/llama-addon.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/src/CMakeFiles/llama.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/common/CMakeFiles/build_info.dir/all
CMakeFiles/llama-addon.dir/all: llama.cpp/common/CMakeFiles/common.dir/all
	$(MAKE) $(MAKESILENT) -f CMakeFiles/llama-addon.dir/build.make CMakeFiles/llama-addon.dir/depend
	$(MAKE) $(MAKESILENT) -f CMakeFiles/llama-addon.dir/build.make CMakeFiles/llama-addon.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=40,41,42,43,44,45,46,47,48,49,50,51,52,53,54 "Built target llama-addon"
.PHONY : CMakeFiles/llama-addon.dir/all

# Build rule for subdir invocation for target.
CMakeFiles/llama-addon.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 54
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 CMakeFiles/llama-addon.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : CMakeFiles/llama-addon.dir/rule

# Convenience name for target.
llama-addon: CMakeFiles/llama-addon.dir/rule
.PHONY : llama-addon

# codegen rule for target.
CMakeFiles/llama-addon.dir/codegen:
	$(MAKE) $(MAKESILENT) -f CMakeFiles/llama-addon.dir/build.make CMakeFiles/llama-addon.dir/codegen
.PHONY : CMakeFiles/llama-addon.dir/codegen

# clean rule for target.
CMakeFiles/llama-addon.dir/clean:
	$(MAKE) $(MAKESILENT) -f CMakeFiles/llama-addon.dir/build.make CMakeFiles/llama-addon.dir/clean
.PHONY : CMakeFiles/llama-addon.dir/clean

#=============================================================================
# Target rules for target llama.cpp/ggml/src/CMakeFiles/ggml-base.dir

# All Build rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=13,14,15,16,17,18,19,20 "Built target ggml-base"
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all

# Build rule for subdir invocation for target.
llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 8
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/rule

# Convenience name for target.
ggml-base: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/rule
.PHONY : ggml-base

# codegen rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/codegen
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/codegen

# clean rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/clean
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/clean

#=============================================================================
# Target rules for target llama.cpp/ggml/src/CMakeFiles/ggml.dir

# All Build rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
llama.cpp/ggml/src/CMakeFiles/ggml.dir/all: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
llama.cpp/ggml/src/CMakeFiles/ggml.dir/all: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
llama.cpp/ggml/src/CMakeFiles/ggml.dir/all: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=11,12 "Built target ggml"
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml.dir/all

# Build rule for subdir invocation for target.
llama.cpp/ggml/src/CMakeFiles/ggml.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 22
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/ggml/src/CMakeFiles/ggml.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml.dir/rule

# Convenience name for target.
ggml: llama.cpp/ggml/src/CMakeFiles/ggml.dir/rule
.PHONY : ggml

# codegen rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml.dir/codegen
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml.dir/codegen

# clean rule for target.
llama.cpp/ggml/src/CMakeFiles/ggml.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/CMakeFiles/ggml.dir/build.make llama.cpp/ggml/src/CMakeFiles/ggml.dir/clean
.PHONY : llama.cpp/ggml/src/CMakeFiles/ggml.dir/clean

#=============================================================================
# Target rules for target llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir

# All Build rule for target.
llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/build.make llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/build.make llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=23,24,25,26,27,28 "Built target ggml-cpu"
.PHONY : llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all

# Build rule for subdir invocation for target.
llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 14
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/rule

# Convenience name for target.
ggml-cpu: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/rule
.PHONY : ggml-cpu

# codegen rule for target.
llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/build.make llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/codegen

# clean rule for target.
llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/build.make llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/clean

#=============================================================================
# Target rules for target llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir

# All Build rule for target.
llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/build.make llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/build.make llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=21,22 "Built target ggml-blas"
.PHONY : llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all

# Build rule for subdir invocation for target.
llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 10
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/rule

# Convenience name for target.
ggml-blas: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/rule
.PHONY : ggml-blas

# codegen rule for target.
llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/build.make llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/codegen

# clean rule for target.
llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/build.make llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/clean

#=============================================================================
# Target rules for target llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir

# All Build rule for target.
llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/build.make llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/build.make llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=29,30,31,32 "Built target ggml-metal"
.PHONY : llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all

# Build rule for subdir invocation for target.
llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 12
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/rule

# Convenience name for target.
ggml-metal: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/rule
.PHONY : ggml-metal

# codegen rule for target.
llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/build.make llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/codegen
.PHONY : llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/codegen

# clean rule for target.
llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/build.make llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/clean
.PHONY : llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/clean

#=============================================================================
# Target rules for target llama.cpp/src/CMakeFiles/llama.dir

# All Build rule for target.
llama.cpp/src/CMakeFiles/llama.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
llama.cpp/src/CMakeFiles/llama.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml.dir/all
llama.cpp/src/CMakeFiles/llama.dir/all: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
llama.cpp/src/CMakeFiles/llama.dir/all: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
llama.cpp/src/CMakeFiles/llama.dir/all: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/src/CMakeFiles/llama.dir/build.make llama.cpp/src/CMakeFiles/llama.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/src/CMakeFiles/llama.dir/build.make llama.cpp/src/CMakeFiles/llama.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=33,34,35,36,37,38,39 "Built target llama"
.PHONY : llama.cpp/src/CMakeFiles/llama.dir/all

# Build rule for subdir invocation for target.
llama.cpp/src/CMakeFiles/llama.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 29
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/src/CMakeFiles/llama.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/src/CMakeFiles/llama.dir/rule

# Convenience name for target.
llama: llama.cpp/src/CMakeFiles/llama.dir/rule
.PHONY : llama

# codegen rule for target.
llama.cpp/src/CMakeFiles/llama.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/src/CMakeFiles/llama.dir/build.make llama.cpp/src/CMakeFiles/llama.dir/codegen
.PHONY : llama.cpp/src/CMakeFiles/llama.dir/codegen

# clean rule for target.
llama.cpp/src/CMakeFiles/llama.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/src/CMakeFiles/llama.dir/build.make llama.cpp/src/CMakeFiles/llama.dir/clean
.PHONY : llama.cpp/src/CMakeFiles/llama.dir/clean

#=============================================================================
# Target rules for target llama.cpp/common/CMakeFiles/build_info.dir

# All Build rule for target.
llama.cpp/common/CMakeFiles/build_info.dir/all:
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/build_info.dir/build.make llama.cpp/common/CMakeFiles/build_info.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/build_info.dir/build.make llama.cpp/common/CMakeFiles/build_info.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=1,2 "Built target build_info"
.PHONY : llama.cpp/common/CMakeFiles/build_info.dir/all

# Build rule for subdir invocation for target.
llama.cpp/common/CMakeFiles/build_info.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 2
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/common/CMakeFiles/build_info.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/common/CMakeFiles/build_info.dir/rule

# Convenience name for target.
build_info: llama.cpp/common/CMakeFiles/build_info.dir/rule
.PHONY : build_info

# codegen rule for target.
llama.cpp/common/CMakeFiles/build_info.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/build_info.dir/build.make llama.cpp/common/CMakeFiles/build_info.dir/codegen
.PHONY : llama.cpp/common/CMakeFiles/build_info.dir/codegen

# clean rule for target.
llama.cpp/common/CMakeFiles/build_info.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/build_info.dir/build.make llama.cpp/common/CMakeFiles/build_info.dir/clean
.PHONY : llama.cpp/common/CMakeFiles/build_info.dir/clean

#=============================================================================
# Target rules for target llama.cpp/common/CMakeFiles/common.dir

# All Build rule for target.
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/ggml/src/CMakeFiles/ggml.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/ggml/src/ggml-cpu/CMakeFiles/ggml-cpu.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/ggml/src/ggml-blas/CMakeFiles/ggml-blas.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/ggml/src/ggml-metal/CMakeFiles/ggml-metal.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/src/CMakeFiles/llama.dir/all
llama.cpp/common/CMakeFiles/common.dir/all: llama.cpp/common/CMakeFiles/build_info.dir/all
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/common.dir/build.make llama.cpp/common/CMakeFiles/common.dir/depend
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/common.dir/build.make llama.cpp/common/CMakeFiles/common.dir/build
	@$(CMAKE_COMMAND) -E cmake_echo_color "--switch=$(COLOR)" --progress-dir=/Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles --progress-num=3,4,5,6,7,8,9,10 "Built target common"
.PHONY : llama.cpp/common/CMakeFiles/common.dir/all

# Build rule for subdir invocation for target.
llama.cpp/common/CMakeFiles/common.dir/rule: cmake_check_build_system
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 39
	$(MAKE) $(MAKESILENT) -f CMakeFiles/Makefile2 llama.cpp/common/CMakeFiles/common.dir/all
	$(CMAKE_COMMAND) -E cmake_progress_start /Users/qzx/gitspace/node-llama-cpp/llama/localBuilds/mac-arm64-metal-release-b4127/CMakeFiles 0
.PHONY : llama.cpp/common/CMakeFiles/common.dir/rule

# Convenience name for target.
common: llama.cpp/common/CMakeFiles/common.dir/rule
.PHONY : common

# codegen rule for target.
llama.cpp/common/CMakeFiles/common.dir/codegen:
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/common.dir/build.make llama.cpp/common/CMakeFiles/common.dir/codegen
.PHONY : llama.cpp/common/CMakeFiles/common.dir/codegen

# clean rule for target.
llama.cpp/common/CMakeFiles/common.dir/clean:
	$(MAKE) $(MAKESILENT) -f llama.cpp/common/CMakeFiles/common.dir/build.make llama.cpp/common/CMakeFiles/common.dir/clean
.PHONY : llama.cpp/common/CMakeFiles/common.dir/clean

#=============================================================================
# Special targets to cleanup operation of make.

# Special rule to run CMake to check the build system integrity.
# No rule that depends on this can have commands that come from listfiles
# because they might be regenerated.
cmake_check_build_system:
	$(CMAKE_COMMAND) -S$(CMAKE_SOURCE_DIR) -B$(CMAKE_BINARY_DIR) --check-build-system CMakeFiles/Makefile.cmake 0
.PHONY : cmake_check_build_system


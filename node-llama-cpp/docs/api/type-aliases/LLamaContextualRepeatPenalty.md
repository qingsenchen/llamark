# Type Alias: LLamaContextualRepeatPenalty

```ts
type LLamaContextualRepeatPenalty: {
  lastTokens: number;
  punishTokensFilter: (tokens: Token[]) => Token[];
  penalizeNewLine: boolean;
  penalty: number;
  frequencyPenalty: number;
  presencePenalty: number;
};
```

## Type declaration

### lastTokens?

```ts
optional lastTokens: number;
```

Number of recent tokens generated by the model to apply penalties to repetition of.
Defaults to `64`.

### punishTokensFilter()?

```ts
optional punishTokensFilter: (tokens: Token[]) => Token[];
```

#### Parameters

| Parameter | Type |
| ------ | ------ |
| `tokens` | [`Token`](Token.md)[] |

#### Returns

[`Token`](Token.md)[]

### penalizeNewLine?

```ts
optional penalizeNewLine: boolean;
```

Penalize new line tokens.
Enabled by default.

### penalty?

```ts
optional penalty: number;
```

The relative amount to lower the probability of the tokens in `punishTokens` by
Defaults to `1.1`.
Set to `1` to disable.

### frequencyPenalty?

```ts
optional frequencyPenalty: number;
```

For n time a token is in the `punishTokens` array, lower its probability by `n * frequencyPenalty`
Disabled by default (`0`).
Set to a value between `0` and `1` to enable.

### presencePenalty?

```ts
optional presencePenalty: number;
```

Lower the probability of all the tokens in the `punishTokens` array by `presencePenalty`
Disabled by default (`0`).
Set to a value between `0` and `1` to enable.

## Defined in

[types.ts:165](https://github.com/withcatai/node-llama-cpp/blob/6405ee945e792651123189aae2612212095765b6/src/types.ts#L165)
